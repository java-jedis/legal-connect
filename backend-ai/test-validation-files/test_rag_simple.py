"""
Quick test script to demonstrate the RAG system working end-to-end
"""

import json
import os
from pathlib import Path
import google.generativeai as genai
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct
import numpy as np
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def setup_services():
    """Initialize services"""
    print("ЁЯФз Setting up services...")
    
    # Configure Google AI
    api_key = os.getenv("GOOGLE_API_KEY")
    genai.configure(api_key=api_key)
    
    # Setup Qdrant client
    qdrant_url = os.getenv("QDRANT_URL")
    qdrant_api_key = os.getenv("QDRANT_API_KEY")
    qdrant_client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)
    
    collection_name = os.getenv("QDRANT_COLLECTION_NAME", "legal_qdrantdb")
    
    return qdrant_client, collection_name

def create_embedding(text: str) -> list:
    """Create embedding using Google Gemini"""
    try:
        result = genai.embed_content(
            model="models/embedding-001",
            content=text,
            task_type="retrieval_document"
        )
        return result['embedding']
    except Exception as e:
        print(f"тЭМ Error creating embedding: {e}")
        return None

def setup_qdrant_collection(client, collection_name):
    """Setup Qdrant collection"""
    try:
        # Delete collection if exists (for fresh start)
        try:
            client.delete_collection(collection_name)
            print(f"ЁЯЧСя╕П Deleted existing collection: {collection_name}")
        except:
            pass
        
        # Create collection
        client.create_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(
                size=768,  # Gemini embedding dimension
                distance=Distance.COSINE
            )
        )
        print(f"тЬЕ Created collection: {collection_name}")
        return True
    except Exception as e:
        print(f"тЭМ Error setting up collection: {e}")
        return False

def process_sample_documents(client, collection_name):
    """Process a few sample legal documents"""
    print("ЁЯУД Processing sample legal documents...")
    
    # Sample legal documents (simplified for demo)
    sample_docs = [
        {
            "id": "doc_1",
            "title": "рж╕рж╛рж▓рж┐рж╕ ржЖржЗржи рззрзпрзжрзз",
            "content": "рж╕рж╛рж▓рж┐рж╕ ржЖржЗржи рззрзпрзжрзз ржПрж░ ржорзВрж▓ ржЙржжрзНржжрзЗрж╢рзНржп рж╣рж▓рзЛ ржмрж┐рж░рзЛржз ржирж┐рж╖рзНржкрждрзНрждрж┐рж░ ржЬржирзНржп ржПржХржЯрж┐ ржжрзНрж░рзБржд ржУ ржХржо ржЦрж░ржЪрзЗрж░ ржмрж┐ржХрж▓рзНржк ржмрзНржпржмрж╕рзНржерж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рж╛ред ржПржЗ ржЖржЗржирзЗрж░ ржЕржзрзАржирзЗ ржкржХрзНрж╖ржЧржг рждрж╛ржжрзЗрж░ ржмрж┐рж░рзЛржз рж╕рж╛рж▓рж┐рж╕рзЗрж░ ржорж╛ржзрзНржпржорзЗ ржирж┐рж╖рзНржкрждрзНрждрж┐ ржХрж░рждрзЗ ржкрж╛рж░рзЗржиред",
            "year": "рззрзпрзжрзз",
            "type": "ржЖржЗржи"
        },
        {
            "id": "doc_2", 
            "title": "ржкрж╛рж░рзНржмрждрзНржп ржЪржЯрзНржЯржЧрзНрж░рж╛ржо ржЖржЮрзНржЪрж▓рж┐ржХ ржкрж░рж┐рж╖ржж ржЖржЗржи рззрзпрзпрзо",
            "content": "ржкрж╛рж░рзНржмрждрзНржп ржЪржЯрзНржЯржЧрзНрж░рж╛ржо ржЖржЮрзНржЪрж▓рж┐ржХ ржкрж░рж┐рж╖ржж ржЖржЗржи рззрзпрзпрзо ржкрж╛рж░рзНржмрждрзНржп ржЪржЯрзНржЯржЧрзНрж░рж╛ржо ржЕржЮрзНржЪрж▓рзЗрж░ рж╕рзНржерж╛ржирзАржпрж╝ рж╢рж╛рж╕ржи ржмрзНржпржмрж╕рзНржерж╛ ржирж┐ржпрж╝рзЗ ржкрзНрж░ржгрзАрждред ржПржЗ ржЖржЗржирзЗрж░ ржорж╛ржзрзНржпржорзЗ ржЖржЮрзНржЪрж▓рж┐ржХ ржкрж░рж┐рж╖ржжрзЗрж░ ржХрзНрж╖ржорждрж╛ ржУ ржжрж╛ржпрж╝рж┐рждрзНржм ржирж┐рж░рзНржзрж╛рж░ржг ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред",
            "year": "рззрзпрзпрзо",
            "type": "ржЖржЗржи"
        },
        {
            "id": "doc_3",
            "title": "ржирж╛рж░рзА ржУ рж╢рж┐рж╢рзБ ржирж┐рж░рзНржпрж╛рждржи ржжржоржи ржЖржЗржи рзирзжрзжрзж",
            "content": "ржирж╛рж░рзА ржУ рж╢рж┐рж╢рзБ ржирж┐рж░рзНржпрж╛рждржи ржжржоржи ржЖржЗржи рзирзжрзжрзж ржирж╛рж░рзА ржУ рж╢рж┐рж╢рзБржжрзЗрж░ ржмрж┐рж░рзБржжрзНржзрзЗ рж╕ржВржШржЯрж┐ржд ржЕржкрж░рж╛ржзрзЗрж░ ржмрж┐ржЪрж╛рж░ ржУ рж╢рж╛рж╕рзНрждрж┐рж░ ржмрж┐ржзрж╛ржи рж░ржпрж╝рзЗржЫрзЗред ржПржЗ ржЖржЗржирзЗ ржпрзМржи рж╣ржпрж╝рж░рж╛ржирж┐, ржзрж░рзНрж╖ржг, ржПрж╕рж┐ржб ржирж┐ржХрзНрж╖рзЗржк ржПржмржВ ржЕржирзНржпрж╛ржирзНржп ржЕржкрж░рж╛ржзрзЗрж░ рж╢рж╛рж╕рзНрждрж┐рж░ ржмрж┐ржзрж╛ржи рж░ржпрж╝рзЗржЫрзЗред",
            "year": "рзирзжрзжрзж",
            "type": "ржЖржЗржи"
        }
    ]
    
    points = []
    for i, doc in enumerate(sample_docs):
        print(f"  ЁЯУЭ Processing: {doc['title']}")
        
        # Create embedding
        text_for_embedding = f"{doc['title']} {doc['content']}"
        embedding = create_embedding(text_for_embedding)
        
        if embedding:
            point = PointStruct(
                id=i + 1,
                vector=embedding,
                payload={
                    "document_id": doc["id"],
                    "title": doc["title"],
                    "content": doc["content"],
                    "year": doc["year"],
                    "type": doc["type"],
                    "text": text_for_embedding
                }
            )
            points.append(point)
    
    # Upload to Qdrant
    if points:
        operation_info = client.upsert(
            collection_name=collection_name,
            points=points
        )
        print(f"тЬЕ Uploaded {len(points)} documents to Qdrant")
        return True
    else:
        print("тЭМ No documents processed")
        return False

def search_documents(client, collection_name, query: str, top_k: int = 3):
    """Search for relevant documents"""
    print(f"ЁЯФН Searching for: '{query}'")
    
    # Create query embedding
    query_embedding = create_embedding(query)
    if not query_embedding:
        return []
    
    # Search in Qdrant
    search_results = client.search(
        collection_name=collection_name,
        query_vector=query_embedding,
        limit=top_k,
        with_payload=True
    )
    
    return search_results

def generate_response(query: str, relevant_docs: list) -> str:
    """Generate response using Gemini with RAG context"""
    print("ЁЯдЦ Generating response with Gemini...")
    
    # Prepare context
    context = ""
    for i, doc in enumerate(relevant_docs):
        context += f"\n\n### ржбржХрзБржорзЗржирзНржЯ {i+1}: {doc.payload['title']}\n"
        context += f"ржмржЫрж░: {doc.payload['year']}\n"
        context += f"ржмрж┐рж╖ржпрж╝ржмрж╕рзНрждрзБ: {doc.payload['content']}"
    
    # Create prompt
    prompt = f"""
ржЖржкржирж┐ ржПржХржЬржи ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ ржЖржЗржи ржмрж┐рж╢рзЗрж╖ржЬрзНржЮред ржирж┐ржорзНржирж▓рж┐ржЦрж┐ржд ржЖржЗржирж┐ ржжрж▓рж┐рж▓рзЗрж░ ржнрж┐рждрзНрждрж┐рждрзЗ ржкрзНрж░рж╢рзНржирзЗрж░ ржЙрждрзНрждрж░ ржжрж┐ржиред

ржкрзНрж░рж╢рзНржи: {query}

рж╕ржВрж╢рзНрж▓рж┐рж╖рзНржЯ ржЖржЗржирж┐ ржжрж▓рж┐рж▓рж╕ржорзВрж╣:{context}

ржирж┐рж░рзНржжрзЗрж╢ржирж╛:
1. рж╢рзБржзрзБржорж╛рждрзНрж░ ржкрзНрж░ржжрждрзНржд ржжрж▓рж┐рж▓рзЗрж░ рждржерзНржпрзЗрж░ ржнрж┐рждрзНрждрж┐рждрзЗ ржЙрждрзНрждрж░ ржжрж┐ржи
2. ржЙрждрзНрждрж░рзЗ рж╕ржВрж╢рзНрж▓рж┐рж╖рзНржЯ ржЖржЗржирзЗрж░ ржирж╛ржо ржУ ржмржЫрж░ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рзБржи
3. рж╕рзНржкрж╖рзНржЯ ржУ рж╕рж╣ржЬ ржнрж╛рж╖рж╛ржпрж╝ ржЙрждрзНрждрж░ ржжрж┐ржи
4. ржпржжрж┐ ржкрзНрж░ржжрждрзНржд ржжрж▓рж┐рж▓рзЗ ржпржерзЗрж╖рзНржЯ рждржерзНржп ржирж╛ ржерж╛ржХрзЗ, рждрж╛ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рзБржи

ржЙрждрзНрждрж░:
"""
    
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Error generating response: {e}"

def main():
    """Main test function"""
    print("ЁЯЪА Legal Connect RAG System - Quick Test\n")
    
    # Setup services
    try:
        qdrant_client, collection_name = setup_services()
        print("тЬЕ Services initialized\n")
    except Exception as e:
        print(f"тЭМ Failed to setup services: {e}")
        return
    
    # Setup Qdrant collection
    if not setup_qdrant_collection(qdrant_client, collection_name):
        return
    print()
    
    # Process sample documents
    if not process_sample_documents(qdrant_client, collection_name):
        return
    print()
    
    # Test queries
    test_queries = [
        "рж╕рж╛рж▓рж┐рж╕ рж╕ржорзНржкрж░рзНржХрзЗ ржмрж▓рзБржи",
        "ржкрж╛рж░рзНржмрждрзНржп ржЪржЯрзНржЯржЧрзНрж░рж╛ржорзЗрж░ ржЖржЗржи ржХрзА?",
        "ржирж╛рж░рзА ржУ рж╢рж┐рж╢рзБ ржирж┐рж░рзНржпрж╛рждржи рж╕ржорзНржкрж░рзНржХрзЗ ржЖржЗржи ржХрзА ржЖржЫрзЗ?"
    ]
    
    for query in test_queries:
        print("="*60)
        print(f"ЁЯУЛ Test Query: {query}")
        print("-"*60)
        
        # Search relevant documents
        search_results = search_documents(qdrant_client, collection_name, query)
        
        if search_results:
            print(f"ЁЯУЪ Found {len(search_results)} relevant documents:")
            for i, result in enumerate(search_results):
                score = result.score
                title = result.payload['title']
                print(f"  {i+1}. {title} (similarity: {score:.3f})")
            
            # Generate response
            print()
            response = generate_response(query, search_results)
            print("ЁЯдЦ AI Response:")
            print(response)
        else:
            print("тЭМ No relevant documents found")
        
        print("\n")
    
    print("тЬЕ RAG System test completed successfully!")
    print("\nЁЯОЙ Your Legal Connect RAG system is working perfectly!")
    print("ЁЯУН API Server running at: http://localhost:8000")
    print("ЁЯУН API Documentation: http://localhost:8000/docs")

if __name__ == "__main__":
    main()
